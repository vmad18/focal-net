# Focal Modulation Network Implementation

* Utilizes a mechanism called Focal Modulation to compute dependencies across tokens
   as opposed to the conventional Self Attention mechanism.
* Added benefit of translation invariance due to fixed query token.
* It achieves state-of-the-art results in object detection tasks.
  * Outperforms previous MSA based architectures such as Swin

# Paper
* FocalNets: Focus Eyes with Focal Modulation: https://arxiv.org/pdf/2203.11926.pdf
